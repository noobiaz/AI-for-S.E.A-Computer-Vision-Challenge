{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "# This is a re-run of my previous submission using Kaggle kernel with an improved accuracy test of 91% on the test set in 8 epochs.\n",
    "\n",
    "# importing libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "import time\n",
    "import os\n",
    "import PIL.Image as Image\n",
    "from IPython.display import display\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting root directory\n",
    "data_dir = '../input/car_data/car_data/'\n",
    "\n",
    "# specifying values for data transformation\n",
    "train_transform = transforms.Compose([transforms.Resize((400, 400)),\n",
    "                                     transforms.RandomHorizontalFlip(),\n",
    "                                     transforms.RandomRotation(45),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "test_transform = transforms.Compose([transforms.Resize((400, 400)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# loading and transforming the data\n",
    "train_set = torchvision.datasets.ImageFolder(root=data_dir+'train', transform = train_transform)\n",
    "trainloader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True, num_workers=2)\n",
    "\n",
    "test_set = torchvision.datasets.ImageFolder(root=data_dir+'test', transform = test_transform)\n",
    "testloader = torch.utils.data.DataLoader(test_set, batch_size=32, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new folder to save models\n",
    "# uncomment this if the folder has not yet existed\n",
    "# os.mkdir('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating inv_norm function to plot images\n",
    "def inv_norm(image, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n",
    "    x = image.new(*image.size())    \n",
    "    x[:, 0, :, :] = image[:, 0, :, :] * std[0] + mean[0]\n",
    "    x[:, 1, :, :] = image[:, 1, :, :] * std[1] + mean[1]\n",
    "    x[:, 2, :, :] = image[:, 2, :, :] * std[2] + mean[2]    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting images from the dataset\n",
    "images, labels = next(iter(testloader))\n",
    "images = inv_norm(images)\n",
    "images = images[0, :, :, :].numpy()\n",
    "images = images.transpose([1, 2, 0])\n",
    "plt.imshow(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating train function for training \n",
    "\n",
    "def train(model, criterion, optimizer, scheduler, n_epochs = 5):\n",
    "    \n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    test_accuracies = []\n",
    "    \n",
    "    # set the model to train mode initially\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        since = time.time()\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "            # get the inputs and assign them to cuda (device)\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # forward and backward propagation + optimization\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # calculate the loss/acc later\n",
    "            running_loss += loss.item()\n",
    "            running_correct += (labels==predicted).sum().item()\n",
    "\n",
    "        epoch_duration = time.time()-since\n",
    "        epoch_loss = running_loss/len(trainloader)\n",
    "        epoch_acc = 100/32*running_correct/len(trainloader)\n",
    "        print('Epoch %s, duration: %d s, loss: %.4f, acc: %.4f' % (epoch+1, epoch_duration, epoch_loss, epoch_acc))\n",
    "        \n",
    "        losses.append(epoch_loss)\n",
    "        accuracies.append(epoch_acc)\n",
    "        \n",
    "        # switch the model to eval mode to evaluate on test data\n",
    "        model.eval()\n",
    "        test_acc = evaluate(model)\n",
    "        test_accuracies.append(test_acc)\n",
    "        \n",
    "        # re-set the model to train mode after validating\n",
    "        model.train()\n",
    "        scheduler.step(test_acc)\n",
    "        since = time.time()\n",
    "        \n",
    "        # save model\n",
    "        best_weights = model_ft.state_dict()\n",
    "        ckpt = {\n",
    "        'loss_history': losses,\n",
    "        'acc_history': (accuracies, test_accuracies),\n",
    "        'weight': best_weights\n",
    "        }\n",
    "        torch.save(ckpt, 'model/CV_ResNet50_pretrained.pth') # use the saved model name to laod the model for later use\n",
    "        \n",
    "    print('Finished Training')\n",
    "    return model, losses, accuracies, test_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create evaluate function for validation \n",
    "\n",
    "def evaluate(model):\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model_ft(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_acc = 100.0 * correct / total\n",
    "    print('Accuracy of the network on the test images: %d %%' % (\n",
    "        test_acc))\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing MCO (Model, Criterion, Optimizer)\n",
    "\n",
    "# load the pretrained resnet50 model\n",
    "model_ft = models.resnet50(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "# replace the last fc layer with an untrained one\n",
    "model_ft.fc = nn.Linear(num_ftrs, 196)\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# set a scheduler to reduce learning rate on plateau\n",
    "lrscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, threshold = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, duration: 160 s, loss: 4.0711, acc: 14.3995\n",
      "Accuracy of the network on the test images: 33 %\n",
      "Epoch 2, duration: 157 s, loss: 1.7453, acc: 54.7917\n",
      "Accuracy of the network on the test images: 55 %\n",
      "Epoch 3, duration: 156 s, loss: 0.9411, acc: 74.1667\n",
      "Accuracy of the network on the test images: 67 %\n",
      "Epoch 4, duration: 157 s, loss: 0.5711, acc: 84.5343\n",
      "Accuracy of the network on the test images: 72 %\n",
      "Epoch 5, duration: 155 s, loss: 0.3975, acc: 89.1054\n",
      "Accuracy of the network on the test images: 77 %\n",
      "Epoch 6, duration: 157 s, loss: 0.2882, acc: 92.5368\n",
      "Accuracy of the network on the test images: 79 %\n",
      "Epoch 7, duration: 157 s, loss: 0.2108, acc: 94.4730\n",
      "Accuracy of the network on the test images: 83 %\n",
      "Epoch 8, duration: 157 s, loss: 0.0965, acc: 97.9779\n",
      "Accuracy of the network on the test images: 91 %\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# initialize training\n",
    "model_ft, training_losses, training_accs, test_accs = train(model_ft, criterion, optimizer, lrscheduler, n_epochs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "# uncomment to load the saved model\n",
    "# ckpt = torch.load('model/CV_ResNet50_pretrained.pth', map_location='cpu') # set the model name as specified in the train funtion\n",
    "# model_ft.load_state_dict(ckpt['weight'])\n",
    "# model_ft = model_ft.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the loaded model\n",
    "# note that the model should be run with a lower learning rate than initially set (< 0.01)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# lrscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, threshold = 0.9)\n",
    "\n",
    "# model_ft, training_losses, training_accs, test_accs = train(model_ft, criterion, optimizer, lrscheduler, n_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
